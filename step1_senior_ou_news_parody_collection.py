import os
import feedparser
from datetime import datetime, timedelta
from anthropic import Anthropic
from anthropic._exceptions import OverloadedError
from dotenv import load_dotenv
from common_utils import get_gsheet, get_gspread_client, get_kst_now
from difflib import SequenceMatcher
import json
import re
from pathlib import Path
import time
import gspread
import pandas as pd
# from newspaper import Article, Config  # newspaper3k ì„¤ì¹˜ í•„ìš”: pip install newspaper3k
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Any
from anthropic.types import MessageParam

# .env íŒŒì¼ì˜ ì ˆëŒ€ ê²½ë¡œë¥¼ ì§€ì •í•˜ì—¬ ë¡œë“œ
env_path = Path('.') / '.env'
load_dotenv(dotenv_path=env_path, verbose=True)

# Claude AI API í‚¤
CLAUDE_API_KEY = os.getenv('CLAUDE_API_KEY')
if not CLAUDE_API_KEY:
    raise ValueError("CLAUDE_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì˜ í˜„ì¬ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì ˆëŒ€ ê²½ë¡œ ìƒì„±
SCRIPT_DIR = Path(__file__).resolve().parent

def parse_rawdata(file_path='asset/rawdata.txt') -> dict[str, Any]:
    """rawdata.txt íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ ì„¤ì •ê°’ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    config: dict[str, Any] = {'rss_urls': []}
    current_section = None
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                if line.startswith('[') and line.endswith(']'):
                    current_section = line[1:-1]
                elif current_section == 'ì—°í•©ë‰´ìŠ¤RSS':
                    config['rss_urls'].append(line)
                elif ':' in line:
                    key, value = line.split(':', 1)
                    k = key.strip()
                    if k == 'rss_urls':
                        continue
                    config[k] = value.strip()
    except FileNotFoundError:
        print(f"ì˜¤ë¥˜: ì„¤ì • íŒŒì¼({file_path})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return {}
    except Exception as e:
        print(f"ì˜¤ë¥˜: ì„¤ì • íŒŒì¼({file_path}) íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {}
    return config

# êµ¬ê¸€ ì‹œíŠ¸ ì„¤ì •
WRITE_SHEET_NAME = 'senior_ou_news_parody_v3'
DISCLAIMER = "ë©´ì±…ì¡°í•­ : íŒ¨ëŸ¬ë””/íŠ¹ì •ê¸°ê´€,ê°œì¸ê³¼ ë¬´ê´€/íˆ¬ìì¡°ì–¸ì•„ë‹˜/ì¬ë¯¸ëª©ì "
SOURCE_PREFIX = "https://gnews/" # ì¶œì²˜ URL ì ‘ë‘ì‚¬

def get_article_content(url):
    """ì£¼ì–´ì§„ URLì˜ ë‰´ìŠ¤ ë³¸ë¬¸ì„ ìŠ¤í¬ë˜í•‘í•©ë‹ˆë‹¤."""
    try:
        user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36'
        # config = Config() # newspaper3k ì‚¬ìš© ì‹œ ì£¼ì„ í•´ì œ
        # config.browser_user_agent = user_agent
        # config.request_timeout = 10
        
        # article = Article(url, config=config) # newspaper3k ì‚¬ìš© ì‹œ ì£¼ì„ í•´ì œ
        # article.download()
        # article.parse()
        # return {'url': url, 'title': article.title, 'text': article.text, 'publish_date': article.publish_date}
        # newspaper3k ì‚¬ìš© ì‹œ ì£¼ì„ í•´ì œ
        return {'url': url, 'title': 'N/A', 'text': 'N/A', 'publish_date': datetime.now()}
    except Exception as e:
        print(f"  - (ê²½ê³ ) ê¸°ì‚¬ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {url}, ì˜¤ë¥˜: {e}")
        return None

def fetch_news_from_rss(rss_urls):
    """ì—¬ëŸ¬ RSS í”¼ë“œì—ì„œ ìµœì‹  ë‰´ìŠ¤ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    all_entries = []
    for url in rss_urls:
        print(f"  - RSS í”¼ë“œ í™•ì¸ ì¤‘: {url}")
        feed = feedparser.parse(url)
        for entry in feed.entries:
            entry['source_rss'] = url
            all_entries.append(entry)
    # ì¤‘ë³µ ì œê±° (link ê¸°ì¤€)
    unique_entries = list({entry.link: entry for entry in all_entries}.values())
    print(f"  -> ì´ {len(unique_entries)}ê°œì˜ ê³ ìœ í•œ ë‰´ìŠ¤ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
    return unique_entries

def rank_and_select_news(news_list, num_to_select=30):
    """ë‰´ìŠ¤ ëª©ë¡ì˜ ì¤‘ìš”ë„ë¥¼ í‰ê°€í•˜ê³  ìƒìœ„ Nê°œë¥¼ ì„ íƒí•©ë‹ˆë‹¤."""
    
    CATEGORY_WEIGHTS = {
        'opinion': 1.5, 'politics': 1.4, 'economy': 1.3, 'market': 1.2,
        'local': 1.0, 'health': 0.9
    }
    KEYWORD_WEIGHTS = {
        'ê¸ˆë¦¬': 5, 'ì •ë¶€': 4, 'íŠ¹ê²€': 4, 'ëŒ€í†µë ¹': 4, 'AI': 3, 'ì—°ê¸ˆ': 3,
        'ë¶€ë™ì‚°': 3, 'ë¬¼ê°€': 2
    }

    for news in news_list:
        score = 0
        # 1. ì¹´í…Œê³ ë¦¬ ê°€ì¤‘ì¹˜
        for cat, weight in CATEGORY_WEIGHTS.items():
            if cat in news.get('source_rss', ''):
                score += weight
                break
        
        # 2. í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜
        title = news.get('title', '')
        for keyword, weight in KEYWORD_WEIGHTS.items():
            if keyword in title:
                score += weight
        
        # 3. ìµœì‹ ì„± ê°€ì¤‘ì¹˜ (ìµœê·¼ 24ì‹œê°„ ë‚´ ê¸°ì‚¬ì— ê°€ì‚°ì )
        published_time = news.get('published_parsed')
        if published_time:
            published_dt = datetime.fromtimestamp(time.mktime(published_time))
            if datetime.now() - published_dt < timedelta(days=1):
                score += 2

        news['score'] = score
    
    # ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    sorted_news = sorted(news_list, key=lambda x: x.get('score', 0), reverse=True)
    
    print("\n[2/6] ë‰´ìŠ¤ ì¤‘ìš”ë„ í‰ê°€ ë° ìƒìœ„ 30ê°œ ì„ ì •...")
    for i, news in enumerate(sorted_news[:10]): # ìƒìœ„ 10ê°œë§Œ ì ìˆ˜ í‘œì‹œ
        print(f"  - {i+1}ìœ„ (ì ìˆ˜: {news.get('score', 0):.1f}): {news.title}")
        
    return sorted_news[:num_to_select]

def create_senior_parody_with_claude(news_item, existing_titles):
    """Claude AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œë‹ˆì–´ ë‰´ìŠ¤ íŒ¨ëŸ¬ë”” ìƒì„±"""
    client = Anthropic(api_key=CLAUDE_API_KEY)

    news_title = news_item.get('title', 'ì œëª© ì—†ìŒ')
    news_summary = news_item.get('text', '')[:5000]

    # f-string ë‚´ ë°±ìŠ¬ë˜ì‹œ ë¬¸ë²• ì˜¤ë¥˜ë¥¼ í”¼í•˜ê¸° ìœ„í•´, ì¤‘ë³µ ë°©ì§€ ëª©ë¡ ë¬¸ìì—´ì„ ë¯¸ë¦¬ ìƒì„±í•©ë‹ˆë‹¤.
    if existing_titles:
        # ê° ì œëª© ì•ì— "- "ë¥¼ ë¶™ì´ê³  ì¤„ë°”ê¿ˆìœ¼ë¡œ ì—°ê²°í•©ë‹ˆë‹¤.
        existing_titles_str = "- " + "\n- ".join(existing_titles)
    else:
        existing_titles_str = "ì—†ìŒ"

    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    parody_prompt = f"""# ì˜¤ëŠ˜ì˜ìœ ë¨¸_ë‰´ìŠ¤íŒ¨ëŸ¬ë””_ì‹œë‹ˆì–´V ì œì‘ ì§€ì¹¨ (v2.0)

## ğŸ¯ **ë¯¸ì…˜**
ë‹¹ì‹ ì€ ë†’ì€ í•™ì‹ê³¼ ê²½í—˜ì„ ê°–ì¶˜ ì‹œë‹ˆì–´ ë…ìë¥¼ ìœ„í•œ **ê³ í’ˆê²© ë‰´ìŠ¤ íŒ¨ëŸ¬ë”” ì œì‘ AI**ì…ë‹ˆë‹¤. ì œê³µë˜ëŠ” **ë‰´ìŠ¤ ë³¸ë¬¸ ì „ì²´**ë¥¼ ê¹Šì´ ìˆê²Œ ë¶„ì„í•˜ì—¬, ë‹¨ìˆœí•œ ìœ ë¨¸ë¥¼ ë„˜ì–´ **ì§€ì ì¸ ê³µê°ê³¼ í†µì°°**ì„ ì´ëŒì–´ë‚´ëŠ” í’ˆìœ„ ìˆëŠ” íŒ¨ëŸ¬ë””ë¥¼ ì œì‘í•´ì•¼ í•©ë‹ˆë‹¤.

## ğŸ§  **íŒ¨ëŸ¬ë”” í•µì‹¬ ì² í•™**
- **íƒ€ê²Ÿ ë…ì**: ëŒ€í•™ êµìœ¡ì„ ë°›ì€, ë³´ìˆ˜ì  ì„±í–¥ì„ ê°€ì§„ ë¶„ë“¤ì´ë©°, ì‚¬íšŒ í˜„ìƒì— ëŒ€í•œ ê¹Šì´ ìˆëŠ” ì´í•´ë¥¼ ì¶”êµ¬í•©ë‹ˆë‹¤.
- **íŒ¨ëŸ¬ë”” í†¤ì•¤ë§¤ë„ˆ**:
  - **ì •ë¶€/ê¸°ê´€ ê´€ë ¨**: ë…¸ê³¨ì ì¸ ë¹„ë‚œì´ë‚˜ ê¸‰ì§„ì  í‘œí˜„ì€ ì ˆëŒ€ ê¸ˆë¬¼ì…ë‹ˆë‹¤. ëŒ€ì‹ , **ì€ìœ ì™€ ë°˜ì–´ë²•ì„ í™œìš©í•œ ì‹œë‹ˆì»¬í•œ í’ì**ë¡œ í•œ ìˆ˜ ìœ„ì˜ ë¹„íŒì„ ë³´ì—¬ì£¼ì„¸ìš”. ì ì–ì§€ë§Œ ë¼ˆê°€ ìˆëŠ” ë†ë‹´ì„ êµ¬ì‚¬í•´ì•¼ í•©ë‹ˆë‹¤.
  - **ì¼ë°˜ ì‚¬íšŒ/ê²½ì œ ë‰´ìŠ¤**: í˜„ìƒì˜ ì´ë©´ì„ ê¿°ëš«ê³ , ë…ìê°€ "ì•„, ê·¸ë ‡ì§€!"í•˜ë©° ë¬´ë¦ì„ íƒ ì¹  ë§Œí•œ **í˜„ì‹¤ì ì´ê³  í†µì°°ë ¥ ìˆëŠ” íŒ¨ëŸ¬ë””**ë¥¼ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.
- **ê¶ê·¹ì  ëª©í‘œ**: ì €ê¸‰í•œ ì›ƒìŒì´ ì•„ë‹Œ, **ì§€ì  ìœ í¬ì—ì„œ ë¹„ë¡¯ëœ í’ˆìœ„ ìˆëŠ” ì›ƒìŒ**ì„ ì„ ì‚¬í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

## ğŸ“° ë¶„ì„í•  ë‰´ìŠ¤ ì›ë¬¸
- **ì œëª©:** {news_title}
- **ë³¸ë¬¸:**
{news_summary}

---
## ğŸ“ **ê²°ê³¼ë¬¼ í¬ë§· (ì—„ìˆ˜)**
- **(ì ˆëŒ€ ê·œì¹™) ë‹¤ë¥¸ ì„¤ëª… ì—†ì´, ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”.**
- **(ì ˆëŒ€ ê·œì¹™) ì ˆëŒ€ë¡œ ì´ëª¨ì§€(emoji)ëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.**
- **(ì ˆëŒ€ ê·œì¹™) ê° í•­ëª©ì˜ ê¸€ììˆ˜ ì œí•œì„ ë°˜ë“œì‹œ ì§€ì¼œì£¼ì„¸ìš”.**

```json
{{
  "ou_title": "ì—¬ê¸°ì— [ì˜¤ìœ _Title] ë‚´ìš© (50ì ì´ë‚´)",
  "latte": "ì—¬ê¸°ì— [ë¼ë–¼] ë‚´ìš© (100ì ì´ë‚´)",
  "ou_think": "ì—¬ê¸°ì— [ì˜¤ìœ _Think] ë‚´ìš© (70ì ì´ë‚´)"
}}
```

## ğŸ¨ **ì„¸ë¶€ ì œì‘ ê°€ì´ë“œë¼ì¸**

### **[ou_title] ì‘ì„±ë²• (50ì ì´ë‚´):**
<<<<<<< HEAD
- **ì§§ê³  ì„íŒ©íŠ¸ ìˆëŠ” í›„í‚¹ ë¬¸êµ¬ ì‚¬ìš©**: ê¸°ì¡´ì˜ "ì¶©ê²©", "ê²½ì•…" ê°™ì€ ë‹¨ì¡°ë¡œìš´ í‘œí˜„ ëŒ€ì‹ , ì•„ë˜ ì˜ˆì‹œì²˜ëŸ¼ ì§§ê³  í˜„ì‹¤ì ì¸ í›„í‚¹ ë¬¸êµ¬ë¥¼ ì°½ì˜ì ìœ¼ë¡œ ì¡°í•©í•˜ì—¬ ì œëª©ì„ ë§Œë“œì„¸ìš”.
- **ê°íƒ„í˜•**: "ì´ê²Œ ë§ë‚˜?", "ë§ì´ ë˜ë‚˜?", "ì„¸ìƒì—ë‚˜...", "ì–´ì´ì—†ë„¤"
- **í˜„ì‹¤í˜•**: "ê²°êµ­ ìš°ë¦¬ë§Œ", "ë˜ ì„œë¯¼ë§Œ", "ì—­ì‹œë‚˜", "ë»”í•œ ìˆ˜ìˆœ"
- **ì„¸ëŒ€í˜•**: "ìš”ì¦˜ ì„¸ìƒ", "ìš°ë¦¬ ë•ŒëŠ”", "ì Šì€ ì• ë“¤", "ì˜›ë‚  ê°™ìœ¼ë©´"
- **ì‹¤ê°í˜•**: "ì²´ê° 100%", "í˜„ì‹¤ ì§ê²©íƒ„", "ì†”ì§ í›„ê¸°", "ì§„ì§œ ì´ìœ "
- **ë‰´ìŠ¤ í•µì‹¬ê³¼ ì—°ê²°**: í›„í‚¹ ë¬¸êµ¬ë¥¼ ë‰´ìŠ¤ í•µì‹¬ ë‚´ìš©ê³¼ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°í•˜ì„¸ìš”. (ì˜ˆ: "AI ì¼ìë¦¬ ëºëŠ”ë‹¤ëŠ”ë°... ë§ì´ ë˜ë‚˜?", "íŠ¸ëŸ¼í”„ ê´€ì„¸ ì˜¬ë¦°ë‹¤ë©´ì„œ... ê²°êµ­ ìš°ë¦¬ë§Œ ì†í•´", "ì–‘ìì»´í“¨í„° ë‚˜ì™”ë‹¤ëŠ”ë°... ìš”ì¦˜ ì„¸ìƒ ë”°ë¼ê°€ê¸° í˜ë“¤ì–´")
=======
- **í’ˆìœ„ ìˆëŠ” í›„í‚¹**: "ê²½ì•…", "ì¶©ê²©" ê°™ì€ ìê·¹ì ì¸ ë‹¨ì–´ ì‚¬ìš©ì„ ì¤„ì´ê³ , "í¥ë¯¸ë¡­êµ°ìš”", "ìƒê°í•´ë³¼ ë¬¸ì œì…ë‹ˆë‹¤", "ì´ê±¸ ì´ë ‡ê²Œ í•´ì„í•˜ë„¤?", "ê¸€ì„ìš”..." ë“± **ì§€ì  í˜¸ê¸°ì‹¬ì„ ìœ ë°œí•˜ëŠ” ë¬¸êµ¬**ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
- **í•µì‹¬ ì°Œë¥´ê¸°**: ë‰´ìŠ¤ ë³¸ë¬¸ì˜ í•µì‹¬ì„ ê¿°ëš«ëŠ” ì§ˆë¬¸ì´ë‚˜ ë°˜ì–´ì  ê°íƒ„ì‚¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. (ì˜ˆ: "ì°¸ìœ¼ë¡œ ì‹œì˜ì ì ˆí•œ ëŒ€ì±…ì´ ì•„ë‹ ìˆ˜ ì—†ë„¤ìš”.")
>>>>>>> 8b9b788862eb7149931ff171aa490a5a86e05468

### **[ë¼ë–¼] ì‘ì„±ë²• (100ì ì´ë‚´):**
- **"ì™•ë…„ì—ëŠ”..."**: ë³¸ë¬¸ ë‚´ìš©ê³¼ ê´€ë ¨ëœ ê³¼ê±°ì˜ ê²½í—˜ì„ í˜„ì¬ì™€ ë¹„êµí•˜ë©° **ì—­ì‚¬ì  ê´€ì ì´ë‚˜ ë³€í™”ì˜ ì•„ì´ëŸ¬ë‹ˆ**ë¥¼ ë‹´ì•„ë‚´ì„¸ìš”. (ì˜ˆ: "ì™•ë…„ì—ëŠ” ì‚ì‚ë§Œ ìš¸ë ¤ë„ ì„¤ë œëŠ”ë°, ì´ì   ì¸ê³µì§€ëŠ¥ì´ ë§ì„ ê±°ëŠ” ì„¸ìƒì´ë¼ë‹ˆ.")
- **ì ì–ì€ ë§íˆ¬**: "~í–ˆë‹¤ì˜¤", "~ë¼ë”êµ°", "~ì¼ì„¸" ë“± ì—°ë¥œì´ ëŠê»´ì§€ëŠ” ì ì–ì€ ì–´ì¡°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

### **[ì˜¤ìœ _Think] ì‘ì„±ë²• (70ì ì´ë‚´):**
- **ì§€ì‹ì¸ì˜ ì‹œê°**: ë‹¨ìˆœí•œ í‘¸ë…ì„ ë„˜ì–´, **ê²½ì œ ì›ë¦¬ë‚˜ ì‚¬íšŒ í˜„ìƒì— ê¸°ë°˜í•œ ëƒ‰ì² í•˜ê³  ì‹œë‹ˆì»¬í•œ ë¶„ì„**ì„ ë‹´ì•„ë‚´ì„¸ìš”. (ì˜ˆ: "ê²°êµ­ ìˆ˜ìš”ì™€ ê³µê¸‰ì˜ ë²•ì¹™ ì•„ë‹ˆê² ì†Œ. ë§ì€ ì‰¬ì›Œë„ ì§€ê°‘ì€ ì–‡ì•„ì§€ë‹ˆ.")
- **ì€ìœ ì™€ í’ì**: "ê²‰ìœ¼ë¡œëŠ” ê·¸ëŸ´ì‹¸í•˜ì§€ë§Œ, ì†ë‚´ëŠ” ë»”í•œ ê²ƒ", "ê³ ìƒí•œ ë§ë¡œ í¬ì¥í–ˆì§€ë§Œ, ê²°êµ­ì€..." ë“± í˜„ìƒì˜ ì´ë©´ì„ ê¼¬ì§‘ëŠ” í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”.

### **ê°ì • í‘œí˜„ í•„ìˆ˜ ì‚¬ìš©:**
- ë‰´ìŠ¤ë§ˆë‹¤ ??, !!, ..., ã…‹ã…‹, ã… ã…  ë“±ì„ 2~3ê°œ ì´ìƒ **ì ˆì œë˜ê³  í’ˆìœ„ ìˆê²Œ** ì¡°í•©í•˜ì—¬ ê°ì •ì„ í‘œí˜„í•´ì£¼ì„¸ìš”. (ì˜ˆ: 'ã…‹ã…‹ã…‹'ë³´ë‹¤ëŠ” 'ã…‹ã…‹' ë˜ëŠ” 'í—ˆí—ˆ...'ê°€ ì ì ˆí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.)

## âœï¸ **(ë§¤ìš° ì¤‘ìš”) ì¤‘ë³µ íŒ¨ëŸ¬ë”” ë°©ì§€**
- ì•„ë˜ëŠ” ì´ë¯¸ ìƒì„±ëœ íŒ¨ëŸ¬ë”” ì œëª©ë“¤ì…ë‹ˆë‹¤.
- **ì ˆëŒ€ë¡œ ì•„ë˜ ëª©ë¡ê³¼ ìœ ì‚¬í•œ ë‚´ìš©ì´ë‚˜ ìŠ¤íƒ€ì¼ì˜ `ou_title`ì„ ë§Œë“¤ì§€ ë§ˆì„¸ìš”.**
- ì™„ì „íˆ ìƒˆë¡­ê³ , ì°½ì˜ì ì¸ ì œëª©ì„ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.

### ğŸ“œ ì´ë¯¸ ìƒì„±ëœ ì œëª© ëª©ë¡:
{existing_titles_str}
"""

    messages: List[MessageParam] = [
        {"role": "user", "content": parody_prompt}
    ]

    max_retries = 3
    retry_delay = 5  # seconds
    for attempt in range(max_retries):
        try:
            response = client.messages.create(
                model="claude-3-5-sonnet-20240620",
                max_tokens=2000,
                temperature=0.8,
                messages=messages
            )
            if response.content:
                first = response.content[0]
                if isinstance(first, dict) and 'text' in first:
                    return first['text']
                else:
                    return str(first)
            return ""
        except OverloadedError as e:
            if attempt < max_retries - 1:
                print(f"  - (ê²½ê³ ) Claude AIê°€ ê³¼ë¶€í•˜ ìƒíƒœì…ë‹ˆë‹¤. {retry_delay}ì´ˆ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤... ({attempt + 1}/{max_retries})")
                time.sleep(retry_delay)
                retry_delay *= 2  # Exponential backoff
            else:
                print(f"  - (ì˜¤ë¥˜) Claude AI ê³¼ë¶€í•˜ë¡œ íŒ¨ëŸ¬ë”” ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
                return ""
        except Exception as e:
            print(f"  - (ì˜¤ë¥˜) Claude AI ìš”ì²­ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return ""
    return ""

def save_results_to_gsheet(client, parody_data_list, spreadsheet_id, worksheet_name):
    """ìƒì„±ëœ íŒ¨ëŸ¬ë”” ê²°ê³¼ë¥¼ êµ¬ê¸€ ì‹œíŠ¸ì— ëˆ„ì í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        spreadsheet = client.open_by_key(spreadsheet_id)
        try:
            worksheet = spreadsheet.worksheet(worksheet_name)
        except gspread.WorksheetNotFound:
            # ì›Œí¬ì‹œíŠ¸ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ë§Œë“­ë‹ˆë‹¤.
            worksheet = spreadsheet.add_worksheet(title=worksheet_name, rows=1, cols=20)
            print(f"  - ìƒˆ ì›Œí¬ì‹œíŠ¸ '{worksheet_name}'ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")

        # ì‹œíŠ¸ê°€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , ë¹„ì–´ìˆë‹¤ë©´ í—¤ë” ì¶”ê°€
        if not worksheet.get_all_values():
            headers = ['today', 'ou_title', 'original_title', 'latte', 'ou_think', 'disclaimer', 'source_url']
            worksheet.append_row(headers)
            print("  - ì‹œíŠ¸ê°€ ë¹„ì–´ìˆì–´ í—¤ë”ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.")
        
        rows_to_upload = []
        today_str = get_kst_now().strftime('%Y-%m-%d, %a').lower()

        for p_data in parody_data_list:
            row = [
                today_str,
                p_data.get('ou_title', ''),
                p_data.get('original_title', ''),
                p_data.get('latte', ''),
                p_data.get('ou_think', ''),
                DISCLAIMER,
                p_data.get('original_link', '')
            ]
            rows_to_upload.append(row)
        
        if rows_to_upload:
            worksheet.append_rows(rows_to_upload)
            print(f"  -> êµ¬ê¸€ ì‹œíŠ¸ '{worksheet_name}'ì— {len(rows_to_upload)}ê°œ ë°ì´í„° ì¶”ê°€ ì €ì¥ ì™„ë£Œ!")
        else:
            print("  -> êµ¬ê¸€ ì‹œíŠ¸ì— ì¶”ê°€í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"  ! êµ¬ê¸€ ì‹œíŠ¸ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

def main():
    start_time = time.time()
    print("="*50)
    print("ì‹œë‹ˆì–´ ë‰´ìŠ¤ íŒ¨ëŸ¬ë”” ìë™ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    print(f"ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*50)

    # 1. ì„¤ì • ë¡œë“œ
    print("\n[1/6] ì„¤ì • íŒŒì¼(asset/rawdata.txt) ë¡œë“œ ì¤‘...")
    config = parse_rawdata(str(SCRIPT_DIR / 'asset/rawdata.txt'))
    if not config or not config.get('rss_urls'):
        print("  ! ì„¤ì • íŒŒì¼ì— [ì—°í•©ë‰´ìŠ¤RSS] ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    if not config or 'íŒ¨ëŸ¬ë””ê²°ê³¼_ìŠ¤í”„ë ˆë“œì‹œíŠ¸_ID' not in config:
        print("  ! ì„¤ì • íŒŒì¼ì— 'íŒ¨ëŸ¬ë””ê²°ê³¼_ìŠ¤í”„ë ˆë“œì‹œíŠ¸_ID' ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    # 2. RSS í”¼ë“œì—ì„œ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
    print("\n[2/6] RSS í”¼ë“œì—ì„œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
    all_news_entries = fetch_news_from_rss(config['rss_urls'])
    
    # 3. ë‰´ìŠ¤ ì¤‘ìš”ë„ í‰ê°€ ë° ì„ íƒ
    card_count = config.get('ì¹´ë“œë‰´ìŠ¤_ê°œìˆ˜', 30)
    if isinstance(card_count, list):
        card_count = 30
    else:
        try:
            card_count = int(card_count)
        except Exception:
            card_count = 30
    selected_news = rank_and_select_news(all_news_entries, card_count)
    
    # 4. ì„ íƒëœ ë‰´ìŠ¤ì˜ ë³¸ë¬¸ ìŠ¤í¬ë˜í•‘
    print("\n[3/6] ì„ íƒëœ ë‰´ìŠ¤ì˜ ì „ì²´ ë³¸ë¬¸ ìŠ¤í¬ë˜í•‘ ì¤‘...")
    scraped_articles = []
    with ThreadPoolExecutor(max_workers=10) as executor:
        future_to_url = {executor.submit(get_article_content, news.link): news for news in selected_news}
        for future in as_completed(future_to_url):
            result = future.result()
            if result and result['text']:
                original_news_item = future_to_url[future]
                result['source_rss'] = original_news_item.get('source_rss')
                result['original_link'] = original_news_item.link
                scraped_articles.append(result)
                print(f"  - ìŠ¤í¬ë˜í•‘ ì™„ë£Œ: {result['title'][:30]}...")
            time.sleep(0.1) # ì„œë²„ ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì•½ê°„ì˜ ë”œë ˆì´
    print(f"  -> ì´ {len(scraped_articles)}ê°œ ê¸°ì‚¬ì˜ ë³¸ë¬¸ì„ ì„±ê³µì ìœ¼ë¡œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")

    # 5. Claude AIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ íŒ¨ëŸ¬ë”” ìƒì„±
    print("\n[4/6] Claude AIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ íŒ¨ëŸ¬ë”” ìƒì„± ì¤‘...")
    parody_results = []
    existing_titles = []
    with ThreadPoolExecutor(max_workers=5) as executor:
        future_to_article = {executor.submit(create_senior_parody_with_claude, article, existing_titles): article for article in scraped_articles}
        
        for i, future in enumerate(as_completed(future_to_article)):
            article = future_to_article[future]
            print(f"  - íŒ¨ëŸ¬ë”” ìƒì„± ì¤‘ ({i+1}/{len(scraped_articles)}): {article['title'][:30]}...")
            
            try:
                parody_json_str = future.result()
                if not parody_json_str:
                    continue

                # Claude ì‘ë‹µì—ì„œ JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (```json ... ``` í•¸ë“¤ë§)
                clean_str = parody_json_str.strip()
                if clean_str.startswith("```json"):
                    clean_str = clean_str[7:].strip()
                if clean_str.endswith("```"):
                    clean_str = clean_str[:-3].strip()
                
                try:
                    parody_data = json.loads(clean_str)
                    
                    # ì¤‘ë³µ ë° ìœ ì‚¬ë„ ê²€ì‚¬
                    is_duplicate = False
                    if 'ou_title' in parody_data:
                        current_title = parody_data['ou_title']
                        for title in existing_titles:
                            if SequenceMatcher(None, current_title, title).ratio() > 0.85:
                                is_duplicate = True
                                print(f"  - (ê²½ê³ ) ìœ ì‚¬í•œ ì œëª©ì´ ì´ë¯¸ ì¡´ì¬í•˜ì—¬ ê±´ë„ˆëœë‹ˆë‹¤: {current_title}")
                                break
                        
                        if not is_duplicate:
                            parody_data['original_title'] = article['title']
                            parody_data['original_link'] = article['url']
                            parody_results.append(parody_data)
                            existing_titles.append(current_title)
                    else:
                        print(f"  - (ê²½ê³ ) ì‘ë‹µì— 'ou_title'ì´ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤: {clean_str}")

                except json.JSONDecodeError:
                    print(f"  - (ê²½ê³ ) Claude AIì˜ ì‘ë‹µì´ ìœ íš¨í•œ JSONì´ ì•„ë‹™ë‹ˆë‹¤: {parody_json_str}")
                    continue

            except Exception as e:
                print(f"  - (ì˜¤ë¥˜) íŒ¨ëŸ¬ë”” ìƒì„± ì‘ì—… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {article['title']}, {e}")

    print(f"  -> ì´ {len(parody_results)}ê°œì˜ ê³ ìœ í•œ íŒ¨ëŸ¬ë””ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")

    # 6. êµ¬ê¸€ ì‹œíŠ¸ì— ê²°ê³¼ ì €ì¥
    print("\n[5/6] ìƒì„±ëœ íŒ¨ëŸ¬ë”” ê²°ê³¼ë¥¼ êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥ ì¤‘...")
    try:
        g_client = get_gspread_client()
        save_results_to_gsheet(g_client, parody_results, config['íŒ¨ëŸ¬ë””ê²°ê³¼_ìŠ¤í”„ë ˆë“œì‹œíŠ¸_ID'], WRITE_SHEET_NAME)
    except Exception as e:
        print(f"  ! êµ¬ê¸€ ì¸ì¦ ë˜ëŠ” ì‹œíŠ¸ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")

    # 7. ì¢…ë£Œ
    end_time = time.time()
    print("\n[6/6] ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
    print(f"ì´ ì†Œìš” ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
    print("="*50)

if __name__ == "__main__":
    main() 